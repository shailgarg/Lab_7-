{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWbKpKs2aL80",
        "outputId": "05353ceb-a857-43ba-dd46-9d9698421656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            " 819     2\n",
            "0       2\n",
            "370     2\n",
            "538     2\n",
            "827     2\n",
            "       ..\n",
            "406     1\n",
            "791     1\n",
            "222     1\n",
            "1171    1\n",
            "1112    1\n",
            "Name: count, Length: 1193, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Perceptron Parameters: {'penalty': 'l2', 'alpha': 0.0001}\n",
            "Perceptron Test Accuracy: 0.008333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best MLP Parameters: {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.01, 'activation': 'relu'}\n",
            "MLP Test Accuracy: 0.0125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your dataset\n",
        "dataset = pd.read_excel('/content/ML dataset.xlsx')  # Update the file path accordingly\n",
        "\n",
        "if 'Telugu' in dataset.columns and 'Hindi' in dataset.columns:\n",
        "    X = dataset['Telugu']  # Telugu sentences\n",
        "    y = dataset['Hindi']   # Hindi translations\n",
        "else:\n",
        "    # Fallback: Use the first column as Telugu and second column as Hindi\n",
        "    X = dataset.iloc[:, 0]  # First column as Telugu\n",
        "    y = dataset.iloc[:, 1]  # Second column as Hindi\n",
        "\n",
        "X = X.fillna('')\n",
        "y = y.fillna('')\n",
        "\n",
        "# Check the distribution of classes\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # Encode Hindi translations\n",
        "\n",
        "class_counts = pd.Series(y_encoded).value_counts()\n",
        "print(\"Class Distribution:\\n\", class_counts)\n",
        "\n",
        "# Text preprocessing using TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_transformed = tfidf.fit_transform(X).toarray()  # Transform Telugu text to feature vectors\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define hyperparameter grids for Perceptron and MLP\n",
        "param_perceptron = {\n",
        "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1.0]\n",
        "}\n",
        "\n",
        "param_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [1e-4, 1e-3, 1e-2],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# Reduce number of splits (cv) to 2 for handling smaller class sizes\n",
        "cv_splits = 2\n",
        "\n",
        "# RandomizedSearchCV for Perceptron\n",
        "rs_perceptron = RandomizedSearchCV(Perceptron(), param_distributions=param_perceptron, n_iter=10, cv=cv_splits, random_state=42)\n",
        "rs_perceptron.fit(X_train, y_train)\n",
        "y_pred_perceptron = rs_perceptron.predict(X_test)\n",
        "accuracy_perceptron = accuracy_score(y_test, y_pred_perceptron)\n",
        "print(\"Best Perceptron Parameters:\", rs_perceptron.best_params_)\n",
        "print(\"Perceptron Test Accuracy:\", accuracy_perceptron)\n",
        "\n",
        "# RandomizedSearchCV for MLP\n",
        "rs_mlp = RandomizedSearchCV(MLPClassifier(), param_distributions=param_mlp, n_iter=10, cv=cv_splits, random_state=42)\n",
        "rs_mlp.fit(X_train, y_train)\n",
        "y_pred_mlp = rs_mlp.predict(X_test)\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "print(\"Best MLP Parameters:\", rs_mlp.best_params_)\n",
        "print(\"MLP Test Accuracy:\", accuracy_mlp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qQ-C3drijHk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "# from catboost import CatBoostClassifier  # Comment this out if not installed\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming X_train, X_test, y_train, y_test are already defined from the previous part\n",
        "\n",
        "# Encode labels for training data\n",
        "le_train = LabelEncoder()\n",
        "y_train_encoded = le_train.fit_transform(y_train)\n",
        "\n",
        "# Encode labels for test data, handle unseen labels in y_test\n",
        "le_test = LabelEncoder()\n",
        "le_test.classes_ = le_train.classes_  # Use same classes as training\n",
        "\n",
        "try:\n",
        "    y_test_encoded = le_test.transform(y_test)\n",
        "except ValueError as e:\n",
        "    print(\"Warning:\", e)\n",
        "    # Optional: Handle unseen labels in y_test by filtering them out\n",
        "    valid_idx = [i for i, label in enumerate(y_test) if label in le_train.classes_]\n",
        "    X_test = X_test[valid_idx]\n",
        "    y_test = [y_test[i] for i in valid_idx]\n",
        "    y_test_encoded = le_test.transform(y_test)\n",
        "\n",
        "# Define classifiers to be evaluated\n",
        "classifiers = {\n",
        "    'SVC': SVC(),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    # 'CatBoost': CatBoostClassifier(verbose=0),  # Comment this out if not installed\n",
        "    'NaiveBayes': MultinomialNB()\n",
        "}\n",
        "\n",
        "# Dictionary to store the results\n",
        "results = {}\n",
        "\n",
        "# Evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train_encoded)  # Train classifier with encoded labels\n",
        "    y_pred = clf.predict(X_test)  # Predict on test data\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    precision = precision_score(y_test_encoded, y_pred, average='weighted', zero_division=1)\n",
        "    recall = recall_score(y_test_encoded, y_pred, average='weighted', zero_division=1)\n",
        "    f1 = f1_score(y_test_encoded, y_pred, average='weighted', zero_division=1)\n",
        "\n",
        "    # Store the results\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1\n",
        "    }\n",
        "\n",
        "# Convert the results dictionary into a DataFrame for better tabulation\n",
        "results_df = pd.DataFrame(results).transpose()\n",
        "\n",
        "# Print the results table\n",
        "print(results_df)\n",
        "\n",
        "# Optional: Save results to a CSV file\n",
        "# results_df.to_csv('classifier_results.csv')\n"
      ],
      "metadata": {
        "id": "GREZ9fnNaSvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d282618-9167-47a8-f0d9-9061047a9a9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: y contains previously unseen labels: [9, 15, 21, 23, 39, 40, 41, 43, 46, 47, 53, 60, 61, 63, 66, 69, 71, 73, 78, 80, 82, 85, 91, 93, 97, 98, 99, 101, 103, 104, 106, 107, 115, 123, 125, 133, 138, 140, 149, 154, 165, 168, 183, 191, 203, 210, 216, 219, 234, 235, 247, 250, 252, 257, 258, 262, 263, 272, 274, 288, 290, 294, 295, 297, 299, 303, 304, 307, 308, 313, 324, 331, 332, 335, 345, 346, 356, 361, 367, 371, 377, 391, 394, 412, 414, 430, 441, 445, 451, 453, 464, 468, 471, 472, 489, 493, 496, 499, 507, 521, 522, 528, 529, 530, 531, 539, 554, 556, 557, 559, 563, 571, 572, 576, 582, 585, 587, 588, 596, 597, 599, 601, 608, 617, 629, 634, 642, 657, 658, 662, 672, 679, 690, 691, 696, 697, 703, 709, 710, 728, 731, 732, 735, 736, 741, 749, 751, 760, 762, 764, 771, 776, 781, 786, 790, 817, 824, 826, 830, 834, 836, 844, 848, 849, 850, 852, 857, 860, 861, 862, 868, 877, 879, 891, 894, 897, 904, 912, 913, 917, 921, 924, 928, 930, 939, 944, 946, 949, 959, 964, 966, 968, 976, 988, 989, 991, 998, 1005, 1021, 1027, 1029, 1033, 1034, 1037, 1039, 1040, 1043, 1059, 1066, 1067, 1070, 1077, 1080, 1089, 1090, 1092, 1096, 1098, 1101, 1113, 1119, 1120, 1126, 1127, 1132, 1133, 1134, 1135, 1140, 1146, 1148, 1152, 1168, 1178, 1185, 1188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Accuracy  Precision  Recall  F1 Score\n",
            "SVC               0.50        1.0    0.50      0.50\n",
            "DecisionTree      0.75        1.0    0.75      0.75\n",
            "RandomForest      0.75        1.0    0.75      0.75\n",
            "AdaBoost          0.00        1.0    0.00      0.00\n",
            "XGBoost           0.00        1.0    0.00      0.00\n",
            "NaiveBayes        0.00        1.0    0.00      0.00\n"
          ]
        }
      ]
    }
  ]
}